"""
Response builder.

Constructs final user-facing TEXT responses based on
LLM output and execution context.

IMPORTANT:
- TEXT ONLY responses
- No interpretation of LLM behavior
- No intent-based routing for health content
"""

from typing import Any, Dict

from app.chat_service.services.voice_pipeline_service import (
    normalized_response_text,
)
from app.chat_service.utils.logger import get_logger

logger = get_logger(__name__)


def build_response(
    *,
    llm_result: Dict[str, Any],
    context: Dict[str, Any],
    response_mode: str,
    consent: Dict[str, bool],
) -> Dict[str, Any]:
    """
    Build the final user-facing TEXT response.

    Args:
        llm_result: Output generated by the LLM.
        context: Execution context (image analysis, metadata).
        response_mode: Output mode (currently only 'text').
        consent: User consent flags (reserved for future use).

    Returns:
        A dictionary containing the final response message.
    """

    try:
        image_analysis = context.get("image_analysis")

        logger.debug(
            "Building response",
            extra={
                "response_mode": response_mode,
                "has_image_analysis": bool(image_analysis),
            },
        )

        # ---------- IMAGE ANALYSIS ----------
        if image_analysis:
            risk = image_analysis.get("risk", "unknown")
            return {
                "message": _risk_message(risk),
                "disclaimer": (
                    "This information is generated by an AI system and is "
                    "for informational purposes only."
                ),
            }

        # ---------- TEXT RESPONSE ----------
        raw_text = llm_result.get(
            "response_text",
            "I am here with you.",
        )

        intent = llm_result.get("intent")
        severity = llm_result.get("severity", "low")

        if intent == "document_understanding":
            return {
                "message": raw_text,
            }

        #  Normalize ONLY conversational responses
        final_text = normalized_response_text(raw_text, severity)

        return {
            "message": final_text,
        }

    except Exception:
        logger.exception(
            "Failed to build response",
            extra={
                "llm_result": llm_result,
                "context": context,
            },
        )
        return {
            "message": (
                "Something went wrong while generating the response. "
                "Please try again."
            )
        }


def _risk_message(risk: str) -> str:
    """
    Generate a user-friendly message based on image risk level.

    Args:
        risk: Risk classification from image analysis.

    Returns:
        Human-readable risk message.
    """
    if risk == "needs_attention":
        return (
            "This image shows patterns that may need medical attention. "
            "Please consult a qualified healthcare professional."
        )

    return "No critical issues were detected based on this image."
