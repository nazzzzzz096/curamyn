"""
Response builder.

Constructs final user-facing TEXT responses based on
LLM output and execution context.

IMPORTANT:
- NO TTS generation here
- NO audio streaming
- TEXT ONLY responses
"""

from typing import Any, Dict

from app.chat_service.services.voice_pipeline_service import (
    finalize_spoken_text,
)
from app.chat_service.utils.logger import get_logger

logger = get_logger(__name__)


INTENT_DOCUMENT = "document_understanding"
INTENT_HEALTH_ADVICE = "health_advice"


def build_response(
    *,
    llm_result: Dict[str, Any],
    context: Dict[str, Any],
    response_mode: str,
    consent: Dict[str, bool],
) -> Dict[str, Any]:
    """
    Build the final user-facing TEXT response.

    Args:
        llm_result: Output generated by the LLM.
        context: Execution context (image analysis, metadata).
        response_mode: Output mode (currently only 'text').
        consent: User consent flags (reserved for future use).

    Returns:
        A dictionary containing the user-facing message.
    """
    try:
        intent = llm_result.get("intent")
        image_analysis = context.get("image_analysis")

        logger.debug(
            "Building response",
            extra={"intent": intent, "response_mode": response_mode},
        )

        # ---------- IMAGE RESPONSE ----------
        if image_analysis:
            risk = image_analysis.get("risk", "unknown")
            return {
                "message": _risk_message(risk),
                "disclaimer": (
                    "This information is generated by an AI system and is "
                    "for informational purposes only. Please consult a "
                    "qualified healthcare professional."
                ),
            }

        # ---------- OCR DOCUMENT ----------
        if intent == INTENT_DOCUMENT:
            return {
                "message": llm_result.get(
                    "response_text",
                    (
                        "I was able to read the document, but could not "
                        "summarize it clearly."
                    ),
                )
            }

        # ---------- HEALTH ADVICE ----------
        if intent == INTENT_HEALTH_ADVICE:
            return {
                "message": llm_result.get(
                    "response_text",
                    "I'm here to help you.",
                )
            }

        # ---------- GENERAL CHAT ----------
        raw_text = llm_result.get("response_text", "I'm here with you.")
        severity = llm_result.get("severity", "low")

        spoken_text = finalize_spoken_text(raw_text, severity)
        return {"message": spoken_text}

    except Exception as exc:
        logger.exception(
            "Failed to build response",
            extra={
                "llm_result": llm_result,
                "context": context,
            },
        )
        return {
            "message": (
                "Something went wrong while generating the response. "
                "Please try again."
            )
        }


def _risk_message(risk: str) -> str:
    """
    Generate a user-friendly message based on image risk level.

    Args:
        risk: Risk classification returned by image analysis.

    Returns:
        Human-readable risk message.
    """
    if risk == "needs_attention":
        return (
            "This scan shows patterns that may require medical attention. "
            "Please consult a healthcare professional."
        )

    return "No critical abnormalities were detected."


